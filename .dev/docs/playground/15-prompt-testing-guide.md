# Playground: Prompt Testing Guide

**Date**: 2025-11-01
**Purpose**: Help users understand how to effectively test prompts in the PRPM+ Playground
**Audience**: End users, package authors, developers

## Overview

The PRPM+ Playground allows users to test AI prompts before installing them. However, many users may not know how to effectively evaluate whether a prompt performs well for their use case. This document outlines:

1. What users should look for when testing prompts
2. Suggested test inputs for different prompt types
3. UI enhancements to guide users
4. Quality indicators to surface

---

## User Testing Challenges

### Current Problem
When a user opens a prompt in the playground, they see:
- A prompt/rule package (e.g., `@cursor/react-conventions`)
- An input field
- A "Run" button

**Questions users have:**
- â“ "What should I ask?"
- â“ "How do I know if this prompt is good?"
- â“ "What makes a good vs bad response?"
- â“ "Is this better than other similar prompts?"

### Why This Matters
- **Wasted Credits**: Users spend credits on poor test inputs
- **False Negatives**: Users dismiss good prompts due to bad test questions
- **False Positives**: Users install poor prompts that seemed good with lucky tests
- **Confusion**: Users don't know what to look for in responses

---

## Solution: Multi-Layered Guidance

### 1. Suggested Test Inputs (UI Enhancement)

**Implementation**: Show 3-5 suggested test inputs for each package based on its type/category.

#### Example: React Conventions Prompt

**Package**: `@cursor/react-conventions`
**Type**: Rule
**Category**: Frontend

**Suggested Tests**:
```
ğŸ’¡ Try these test inputs:

1. ğŸ¯ Basic: "How should I structure a React component?"
   Tests: Basic understanding of conventions

2. ğŸ¯ Specific: "Show me how to create a form with validation"
   Tests: Practical application of rules

3. ğŸ¯ Edge Case: "How should I handle async data in components?"
   Tests: Depth of knowledge

4. ğŸ¯ Anti-pattern: "Should I use class components or functional?"
   Tests: Modern best practices awareness

5. ğŸ¯ Integration: "How do I integrate this with TypeScript?"
   Tests: Cross-domain knowledge
```

#### Example: Code Review Agent

**Package**: `@prpm/code-reviewer`
**Type**: Agent
**Category**: Development Tools

**Suggested Tests**:
```
ğŸ’¡ Try these test inputs:

1. ğŸ“ Sample Code: "Review this component: [paste code]"
   Tests: Basic review functionality

2. ğŸ› Bug Finding: "Find potential bugs in: [buggy code]"
   Tests: Error detection capability

3. ğŸ¨ Style Check: "Check code style: [messy code]"
   Tests: Convention enforcement

4. ğŸ”’ Security: "Review for security issues: [vulnerable code]"
   Tests: Security awareness

5. âš¡ Performance: "Optimize this code: [slow code]"
   Tests: Performance optimization skills
```

#### Example: TypeScript Best Practices

**Package**: `@typescript/best-practices`
**Type**: Skill
**Category**: Languages

**Suggested Tests**:
```
ğŸ’¡ Try these test inputs:

1. ğŸ“š Explain: "What are TypeScript generics?"
   Tests: Conceptual understanding

2. ğŸ”§ Fix: "How do I fix this type error: [error]"
   Tests: Practical problem-solving

3. ğŸ—ï¸ Design: "How should I type this API response?"
   Tests: Real-world application

4. ğŸš€ Advanced: "Explain conditional types with examples"
   Tests: Advanced knowledge depth

5. ğŸ”„ Compare: "When should I use 'type' vs 'interface'?"
   Tests: Nuanced decision-making
```

---

### 2. Evaluation Criteria (Educational Content)

Show users what to look for in responses:

#### Quality Indicators Checklist

**When evaluating a response, check for:**

**âœ… Accuracy**
- [ ] Information is factually correct
- [ ] Follows current best practices (not outdated)
- [ ] Cites sources or reasoning when applicable
- [ ] No hallucinations or made-up information

**âœ… Relevance**
- [ ] Directly answers your question
- [ ] Stays on topic
- [ ] Provides appropriate level of detail
- [ ] Doesn't include unnecessary tangents

**âœ… Clarity**
- [ ] Easy to understand
- [ ] Well-structured (headings, lists, code blocks)
- [ ] Uses clear language (not overly technical unless needed)
- [ ] Provides examples when helpful

**âœ… Completeness**
- [ ] Addresses all parts of your question
- [ ] Provides context when needed
- [ ] Explains "why" not just "how"
- [ ] Includes edge cases or caveats

**âœ… Actionability**
- [ ] Provides concrete steps or code
- [ ] Shows working examples
- [ ] Explains how to implement suggestions
- [ ] Links to further resources

**âœ… Consistency**
- [ ] Follows the package's stated approach
- [ ] Maintains consistent style/tone
- [ ] Aligns with the prompt's purpose
- [ ] Doesn't contradict itself

---

### 3. Comparison Mode (Feature Enhancement)

**Feature**: Allow users to test multiple prompts side-by-side with the same input.

#### UI Mockup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Playground - Comparison Mode                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Input (shared): "How should I structure React components?" â”‚
â”‚                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  @cursor/react-conventionsâ”‚  @react/component-patterns      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          â”‚                                  â”‚
â”‚  Response A:             â”‚  Response B:                     â”‚
â”‚  - Functional components â”‚  - Use composition               â”‚
â”‚  - Single responsibility â”‚  - Container/Presentational      â”‚
â”‚  - Props validation      â”‚  - Hooks for logic               â”‚
â”‚  ...                     â”‚  ...                             â”‚
â”‚                          â”‚                                  â”‚
â”‚  Credits: 1              â”‚  Credits: 1                      â”‚
â”‚  Tokens: 1,234           â”‚  Tokens: 1,456                   â”‚
â”‚  Time: 3.2s              â”‚  Time: 3.8s                      â”‚
â”‚                          â”‚                                  â”‚
â”‚  ğŸ‘ ğŸ‘  â­ Save          â”‚  ğŸ‘ ğŸ‘  â­ Save                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Which response was better?  [ Response A ] [ Response B ] [ Both Good ] [ Neither ]
```

**Benefits**:
- Users see quality differences directly
- Can compare similar prompts (e.g., two React rule packages)
- Builds intuition for what "good" looks like
- Helps users make informed installation decisions

---

### 4. Example Conversations (Package-Level)

**Implementation**: Package authors include example conversations in their package metadata.

#### Schema Addition

```typescript
// packages/types/src/index.ts
export interface Package {
  // ... existing fields
  examples?: PlaygroundExample[];
}

export interface PlaygroundExample {
  title: string;
  description: string;
  input: string;
  expected_output_summary?: string; // What a good response should include
  tags?: string[]; // e.g., ["basic", "advanced", "debugging"]
}
```

#### Example Usage

```json
{
  "name": "@cursor/react-conventions",
  "version": "1.0.0",
  "examples": [
    {
      "title": "Component Structure",
      "description": "Tests basic understanding of React component organization",
      "input": "How should I structure a React component?",
      "expected_output_summary": "Should mention functional components, single responsibility, hooks, and props validation",
      "tags": ["basic", "structure"]
    },
    {
      "title": "State Management",
      "description": "Tests knowledge of when to use different state solutions",
      "input": "When should I use Redux vs Context vs local state?",
      "expected_output_summary": "Should explain trade-offs, provide decision criteria, and give examples",
      "tags": ["advanced", "state"]
    }
  ]
}
```

#### UI Implementation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Testing: @cursor/react-conventions                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ“š Example Tests (provided by author)                 â”‚
â”‚                                                         â”‚
â”‚  1. Component Structure [basic]                        â”‚
â”‚     "How should I structure a React component?"        â”‚
â”‚     âœ“ Should cover: functional components, hooks, ...  â”‚
â”‚     [Try this example]                                 â”‚
â”‚                                                         â”‚
â”‚  2. State Management [advanced]                        â”‚
â”‚     "When should I use Redux vs Context vs local..."   â”‚
â”‚     âœ“ Should cover: trade-offs, decision criteria, ... â”‚
â”‚     [Try this example]                                 â”‚
â”‚                                                         â”‚
â”‚  Or enter your own question:                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ [Your input here]                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â”‚  [Run]                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5. Quality Scoring (Advanced Feature)

**Feature**: AI-powered quality assessment of responses.

#### Implementation

After each playground run, analyze the response for quality:

```typescript
interface ResponseQualityScore {
  overall: number; // 0-100
  dimensions: {
    accuracy: number; // 0-100
    relevance: number; // 0-100
    clarity: number; // 0-100
    completeness: number; // 0-100
    actionability: number; // 0-100
  };
  flags: string[]; // e.g., ["outdated_info", "missing_examples", "too_verbose"]
  suggestions: string[]; // How to improve the prompt
}
```

#### UI Display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response Quality Analysis                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Overall Score: 85/100  â­â­â­â­                     â”‚
â”‚                                                      â”‚
â”‚  Accuracy:      95  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Excellent  â”‚
â”‚  Relevance:     90  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   Very Good  â”‚
â”‚  Clarity:       80  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     Good       â”‚
â”‚  Completeness:  75  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      Good       â”‚
â”‚  Actionability: 85  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    Very Good  â”‚
â”‚                                                      â”‚
â”‚  âœ“ Strengths:                                       â”‚
â”‚    â€¢ Provides accurate, up-to-date information      â”‚
â”‚    â€¢ Includes working code examples                 â”‚
â”‚    â€¢ Well-structured response                       â”‚
â”‚                                                      â”‚
â”‚  âš  Areas for Improvement:                           â”‚
â”‚    â€¢ Could mention edge cases                       â”‚
â”‚    â€¢ More context on "why" would help               â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Approach**:
```typescript
// Use Claude to analyze Claude's response (meta-analysis)
async function scoreResponse(
  userInput: string,
  promptContent: string,
  aiResponse: string
): Promise<ResponseQualityScore> {
  const analysisPrompt = `
You are analyzing an AI assistant's response for quality. Rate it on:
- Accuracy (factually correct, no hallucinations)
- Relevance (directly answers the question)
- Clarity (well-structured, easy to understand)
- Completeness (addresses all parts of question)
- Actionability (provides concrete examples/steps)

User asked: ${userInput}
Prompt context: ${promptContent}
AI response: ${aiResponse}

Return JSON with scores (0-100) for each dimension and overall.
`;

  // Use a fast model (Haiku/GPT-4o-mini) for cost efficiency
  const analysis = await callAI(analysisPrompt, 'haiku');
  return JSON.parse(analysis);
}
```

---

### 6. Community Testing Patterns

**Feature**: Crowdsource testing insights from the community.

#### Schema

```typescript
export interface CommunityTestInsight {
  package_id: string;
  user_id: string;
  test_input: string;
  response_quality: number; // 1-5 stars
  helpful_count: number; // Upvotes
  tags: string[];
  comment?: string; // Why this test was useful
  created_at: string;
}
```

#### UI Display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Community Test Examples                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Most Helpful Tests from the Community:                â”‚
â”‚                                                         â”‚
â”‚  1. â­â­â­â­â­ (42 helpful)                              â”‚
â”‚     "Create a form with validation and error handling" â”‚
â”‚     ğŸ’¬ "Really shows if the prompt understands..."     â”‚
â”‚     [Try this test]                                    â”‚
â”‚                                                         â”‚
â”‚  2. â­â­â­â­ (38 helpful)                                â”‚
â”‚     "How to handle async operations in components?"    â”‚
â”‚     ğŸ’¬ "Great for testing advanced knowledge"          â”‚
â”‚     [Try this test]                                    â”‚
â”‚                                                         â”‚
â”‚  3. â­â­â­â­ (35 helpful)                                â”‚
â”‚     "Explain the difference between state and props"   â”‚
â”‚     ğŸ’¬ "Good baseline test for beginners"              â”‚
â”‚     [Try this test]                                    â”‚
â”‚                                                         â”‚
â”‚  [See all community tests]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- Users learn from others' testing strategies
- Discover edge cases they wouldn't have thought of
- Build a knowledge base of effective tests
- Gamification: Users get recognition for helpful test inputs

---

### 7. Guided Testing Wizard (Onboarding)

**Feature**: Step-by-step wizard for first-time playground users.

#### Flow

```
Step 1: Welcome
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ® Welcome to the Playground!                 â”‚
â”‚                                                 â”‚
â”‚  Test prompts before installing them.          â”‚
â”‚  We'll guide you through your first test.      â”‚
â”‚                                                 â”‚
â”‚  [Start Tutorial] [Skip]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Choose Package
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Choose a package to test:                     â”‚
â”‚                                                 â”‚
â”‚  â— @cursor/react-conventions (Recommended)     â”‚
â”‚    Popular rule for React development          â”‚
â”‚                                                 â”‚
â”‚  â—‹ @typescript/best-practices                  â”‚
â”‚  â—‹ @prpm/code-reviewer                         â”‚
â”‚                                                 â”‚
â”‚  [Next]                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: Select Test Type
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  What do you want to test?                     â”‚
â”‚                                                 â”‚
â”‚  â— Basic understanding                         â”‚
â”‚    See if the prompt knows the fundamentals    â”‚
â”‚                                                 â”‚
â”‚  â—‹ Practical application                       â”‚
â”‚    Test with a real coding scenario            â”‚
â”‚                                                 â”‚
â”‚  â—‹ Advanced knowledge                          â”‚
â”‚    Check depth of expertise                    â”‚
â”‚                                                 â”‚
â”‚  [Next]                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Use Suggested Input
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Try this test input:                          â”‚
â”‚                                                 â”‚
â”‚  "How should I structure a React component?"   â”‚
â”‚                                                 â”‚
â”‚  This tests if the prompt understands:         â”‚
â”‚  âœ“ Functional vs class components             â”‚
â”‚  âœ“ Component organization                     â”‚
â”‚  âœ“ Best practices                              â”‚
â”‚                                                 â”‚
â”‚  [Run Test (1 credit)]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 5: Evaluate Response
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Response:                                  â”‚
â”‚  [Response shown here...]                      â”‚
â”‚                                                 â”‚
â”‚  Look for:                                     â”‚
â”‚  âœ“ Mentions functional components              â”‚
â”‚  âœ“ Discusses single responsibility             â”‚
â”‚  âœ“ Includes code examples                      â”‚
â”‚  âœ“ Explains reasoning                          â”‚
â”‚                                                 â”‚
â”‚  Did the response cover these points?          â”‚
â”‚  [Yes, looks good] [Missing some] [Poor]       â”‚
â”‚                                                 â”‚
â”‚  [Try another test] [Install package] [Done]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Prompt-Type Specific Guidance

### Rules/Skills

**What to test:**
- âœ… Basic concept understanding
- âœ… Application to real scenarios
- âœ… Edge case handling
- âœ… Best practice recommendations
- âœ… Anti-pattern detection

**Example tests:**
```
1. "Explain [concept]"
2. "How do I [task]?"
3. "What's wrong with this: [bad code]"
4. "When should I use [approach A] vs [approach B]?"
5. "Show me an example of [pattern]"
```

### Agents

**What to test:**
- âœ… Task completion capability
- âœ… Multi-step reasoning
- âœ… Error handling
- âœ… Edge case awareness
- âœ… Output quality

**Example tests:**
```
1. "Review this code: [sample]"
2. "Find bugs in: [buggy code]"
3. "Optimize this function: [slow code]"
4. "Refactor this to: [target pattern]"
5. "Generate tests for: [code]"
```

### Templates

**What to test:**
- âœ… Completeness of output
- âœ… Customization options
- âœ… Following conventions
- âœ… Documentation quality
- âœ… Working state (if code)

**Example tests:**
```
1. "Generate a [type] component"
2. "Create a [pattern] with [feature]"
3. "Scaffold a [project type]"
4. "Make a [artifact] that [requirement]"
5. "Show me variations with [different approach]"
```

### Workflows

**What to test:**
- âœ… Step-by-step process
- âœ… Handles dependencies
- âœ… Error recovery
- âœ… Progress feedback
- âœ… Completion criteria

**Example tests:**
```
1. "Walk me through [process]"
2. "What if [error] happens during [step]?"
3. "How do I customize [part of workflow]?"
4. "Show me the full workflow for [task]"
5. "What are the prerequisites for [workflow]?"
```

---

## UI/UX Recommendations

### Immediate (High Priority)

1. **Show Suggested Test Inputs**
   - Display 3-5 suggested tests for each package
   - Generated based on package type/category
   - One-click to use suggestion

2. **Add "What to Look For" Guidance**
   - Show evaluation criteria after response
   - Highlight key quality indicators
   - Educational tooltip on first use

3. **Comparison Mode**
   - Allow testing 2 prompts side-by-side
   - Same input, different prompts
   - Visual diff of responses

### Short-term (Medium Priority)

4. **Example Conversations from Authors**
   - Package schema supports examples
   - Authors provide 2-3 test cases
   - UI shows examples prominently

5. **Community Test Patterns**
   - Users can save/share test inputs
   - Upvote helpful tests
   - "Most helpful tests" section

6. **Response Quality Indicators**
   - Simple visual indicators (âœ“/âš /âœ—)
   - Length, token count, response time
   - Complexity score (optional)

### Long-term (Lower Priority)

7. **AI-Powered Quality Scoring**
   - Automated response analysis
   - Quality scores on 5 dimensions
   - Improvement suggestions

8. **Testing Wizard for New Users**
   - Guided first-time experience
   - Educational walkthroughs
   - Best practices teaching

9. **Historical Test Results**
   - Save test results per package
   - Compare across versions
   - Track quality over time

---

## Data Schema Additions

### Package Examples

```sql
-- Add examples column to packages table
ALTER TABLE packages ADD COLUMN examples JSONB DEFAULT '[]';

-- Example data structure
UPDATE packages SET examples = '[
  {
    "title": "Component Structure",
    "description": "Tests basic React component organization",
    "input": "How should I structure a React component?",
    "expected_output_summary": "functional components, hooks, props",
    "tags": ["basic", "structure"]
  }
]' WHERE name = 'react-conventions';
```

### Community Test Insights

```sql
CREATE TABLE playground_test_insights (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  package_id UUID NOT NULL REFERENCES packages(id) ON DELETE CASCADE,
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  test_input TEXT NOT NULL,
  response_quality INT CHECK (response_quality BETWEEN 1 AND 5),
  helpful_count INT DEFAULT 0,
  tags TEXT[] DEFAULT '{}',
  comment TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_test_insights_package ON playground_test_insights(package_id);
CREATE INDEX idx_test_insights_helpful ON playground_test_insights(helpful_count DESC);
CREATE INDEX idx_test_insights_quality ON playground_test_insights(response_quality DESC);
```

### Test Insight Votes

```sql
CREATE TABLE playground_test_insight_votes (
  insight_id UUID NOT NULL REFERENCES playground_test_insights(id) ON DELETE CASCADE,
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  created_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (insight_id, user_id)
);
```

---

## API Endpoints Needed

### Get Suggested Tests

```typescript
GET /api/v1/playground/packages/:id/suggested-tests

Response:
{
  "suggested_tests": [
    {
      "title": "Component Structure",
      "description": "Tests basic understanding",
      "input": "How should I structure a React component?",
      "difficulty": "basic",
      "tags": ["structure", "basics"]
    },
    ...
  ],
  "source": "ai_generated" | "author_provided" | "community"
}
```

### Get Community Test Insights

```typescript
GET /api/v1/playground/packages/:id/community-tests

Query params:
- sort: "helpful" | "recent" | "quality"
- limit: number
- offset: number

Response:
{
  "tests": [
    {
      "id": "uuid",
      "test_input": "...",
      "response_quality": 5,
      "helpful_count": 42,
      "tags": ["advanced", "state"],
      "comment": "Really tests depth of knowledge",
      "created_at": "..."
    },
    ...
  ],
  "total": 156
}
```

### Save Test Insight

```typescript
POST /api/v1/playground/test-insights

Body:
{
  "package_id": "uuid",
  "test_input": "How should I...",
  "response_quality": 5,
  "tags": ["useful", "advanced"],
  "comment": "Great test for..."
}

Response:
{
  "id": "uuid",
  "insight": { ... }
}
```

### Vote on Test Insight

```typescript
POST /api/v1/playground/test-insights/:id/vote

Response:
{
  "helpful_count": 43
}
```

---

## Implementation Priority

### Phase 1: Quick Wins (Week 1)
1. âœ… Show 3 hardcoded suggested tests per package type
2. âœ… Add "What to look for" tooltip/card
3. âœ… Display basic metrics (tokens, time, model)

### Phase 2: Author Support (Week 2-3)
4. âœ… Add examples field to package schema
5. âœ… UI to display author-provided examples
6. âœ… Package publish flow includes examples

### Phase 3: Community Features (Week 4-5)
7. âœ… Community test insights schema
8. âœ… API endpoints for insights
9. âœ… UI to browse/submit/vote on tests

### Phase 4: AI Enhancement (Week 6+)
10. âœ… AI-generated suggested tests
11. âœ… Response quality scoring
12. âœ… Comparison mode

---

## Success Metrics

Track these to measure effectiveness:

- **User Engagement**
  - % of playground users who try suggested tests
  - Avg tests per package before install
  - Time spent in playground

- **Quality**
  - User ratings of suggested tests (helpful/not helpful)
  - Community test insight votes
  - Install rate after playground testing

- **Conversion**
  - % users who install after testing
  - % users who buy credits to test more
  - Repeat playground usage

- **Community**
  - # of community test insights submitted
  - Avg votes per insight
  - Active contributors

---

## Conclusion

By providing **guided testing experiences**, we can:
- âœ… Help users make informed decisions
- âœ… Reduce wasted credits on poor tests
- âœ… Educate users on prompt quality
- âœ… Build community knowledge
- âœ… Increase user confidence
- âœ… Improve package discovery

**Next Steps**:
1. Implement Phase 1 (suggested tests UI)
2. Add author examples to package schema
3. Gather user feedback on testing experience
4. Iterate based on usage data

---

**Last Updated**: 2025-11-01
**Status**: ğŸ“‹ Design Document - Ready for Implementation
